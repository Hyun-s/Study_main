{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR10_v2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5bc91b93f2d441d3b36dff344880cec5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ae30aabc8dc54d3c8e80af8dbf8b09af",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f74e13915d4b41dfb47fb84d66ba6433",
              "IPY_MODEL_cb362a2a96b3482ca967e8e644f90302"
            ]
          }
        },
        "ae30aabc8dc54d3c8e80af8dbf8b09af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f74e13915d4b41dfb47fb84d66ba6433": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_63aaa2026f5c4b71b2d9fc284cfb4f99",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2ba116a678a24de78cc95941084c3558"
          }
        },
        "cb362a2a96b3482ca967e8e644f90302": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0613a6f35a5644f991b149fea95584a1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:07&lt;00:00, 22565418.41it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a650805a2b6a4d2fbe6ee9a634b7c3e1"
          }
        },
        "63aaa2026f5c4b71b2d9fc284cfb4f99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2ba116a678a24de78cc95941084c3558": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0613a6f35a5644f991b149fea95584a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a650805a2b6a4d2fbe6ee9a634b7c3e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKvxz-3LswnI"
      },
      "source": [
        "[https://github.com/Hyun-s/SW-AI/tree/master/Deep_learning/CIFAR_10_challenge](https://github.com/Hyun-s/SW-AI/tree/master/Deep_learning/CIFAR_10_challenge)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrWJYU6hPm8L"
      },
      "source": [
        "# CIFAR-10 Challenge\n",
        "학습 전략은 이 논문을 참고하여 설정하였습니다.  \n",
        "1. Learning rate scheduling  \n",
        "아래 논문에서는 Learning rate warmup이라 하여 초기 몇 epoch에서는 Learning rate를 linear하게 키우고, 그 이후는 감소시키는 방법을 추천한다고 합니다.그래서\n",
        "아래의 논문에서는cosine annealing with warm up이라는 lr스케쥴링을 사용하지만, 저는 이와 유사하게 pytorch에서 기본으로 제공하는 도구인 cyclicLR을 사용하였습니다.  \n",
        "2. Data augmentation  \n",
        "Data augmentation 기법으로는 Randomcrop, horizontal flip을 사용하였고 아래 논문에서 나왔던 MixUp이라는 augmentation 기법을 사용하였습니다.   \n",
        "3. FC-layer  \n",
        "FC-layer는 분류 하는 layer로써 CNN의 tra 위하여 4096 -> 100 -> 10 으로 설정하였고, 더 빠른 학습을 위하여 softmax 활성화 함수를 마지막에 추가하였습니다.   \n",
        "\n",
        "[He, Tong, et al. \"Bag of tricks for image classification with convolutional neural networks.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2019.](https://arxiv.org/pdf/1812.01187.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWIfaI0er6M1",
        "outputId": "aed10d6e-9b68-4ced-e7c4-0a71ca8e6afe"
      },
      "source": [
        "import sys\n",
        "print(sys.version_info)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sys.version_info(major=3, minor=7, micro=10, releaselevel='final', serial=0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nO0XgIs3NZC"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import random"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSuaqV8v3Uc_"
      },
      "source": [
        "batch_size = 32\n",
        "learning_rate = 2e-3\n",
        "num_epoch = 200\n",
        "weight_decay=1e-3\n",
        "MixUp_choice = 1\n",
        "MixUp_alpha = 0.4\n",
        "\n",
        "random_seed=42\n",
        "\n",
        "torch.manual_seed(random_seed)\n",
        "torch.cuda.manual_seed(random_seed)\n",
        "torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(random_seed)\n",
        "random.seed(random_seed)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120,
          "referenced_widgets": [
            "5bc91b93f2d441d3b36dff344880cec5",
            "ae30aabc8dc54d3c8e80af8dbf8b09af",
            "f74e13915d4b41dfb47fb84d66ba6433",
            "cb362a2a96b3482ca967e8e644f90302",
            "63aaa2026f5c4b71b2d9fc284cfb4f99",
            "2ba116a678a24de78cc95941084c3558",
            "0613a6f35a5644f991b149fea95584a1",
            "a650805a2b6a4d2fbe6ee9a634b7c3e1"
          ]
        },
        "id": "Skz8LDqy3ous",
        "outputId": "e605432c-a495-46d9-bbb3-960f0f76a823"
      },
      "source": [
        "cifar_train = dset.CIFAR10(\"CIFAR10/\", train=True, transform=transforms.ToTensor(),\n",
        "                            target_transform=None, download=True)\n",
        "cifar_test = dset.CIFAR10(\"CIFAR10/\", train=False, transform=transforms.ToTensor(),\n",
        "                            target_transform=None, download=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to CIFAR10/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5bc91b93f2d441d3b36dff344880cec5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=170498071.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting CIFAR10/cifar-10-python.tar.gz to CIFAR10/\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNpSxgzb8S1L"
      },
      "source": [
        "# v2\n",
        "def ComputeAccr(dloader, imodel):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "    \n",
        "  with torch.no_grad():\n",
        "    for j, [imgs, labels] in enumerate(dloader):\n",
        "      img = Variable(imgs).cuda()\n",
        "      label = Variable(labels).cuda()\n",
        "\n",
        "      output = imodel.forward(img)\n",
        "      _, output_index = torch.max(output, 1)\n",
        "        \n",
        "      total += label.size(0)\n",
        "      correct += (output_index == label).sum().float()\n",
        "  print(\"Accuracy of Test Data: {}\".format(100*correct/total))\n",
        "  return 100*correct/total  "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23eyZSsMPIAv"
      },
      "source": [
        "# cifar-10 augmentation\n",
        "normalize에 사용한 mean, std 수치는 이곳을 참고하여 사용하였습니다.  \n",
        "[reference](https://github.com/facebookarchive/fb.resnet.torch/issues/180) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "zpjfgPzQ3vUV",
        "outputId": "9a8bfc14-c5e3-49c3-a183-c01300b0359a"
      },
      "source": [
        "cifar_train = dset.CIFAR10(\"CIFAR10/\", train=True, \n",
        "                           transform=transforms.Compose([\n",
        "                            transforms.RandomCrop(32, padding=4),\n",
        "                            transforms.RandomHorizontalFlip(),\n",
        "                            transforms.ToTensor(),\n",
        "                            transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
        "                             (0.2023, 0.1994, 0.2010)),\n",
        "                           ]))\n",
        "cifar_test = dset.CIFAR10(\"CIFAR10/\",train=False,\n",
        "                          transform=transforms.Compose([\n",
        "                            transforms.ToTensor(),\n",
        "                            transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
        "                             (0.2023, 0.1994, 0.2010))                                                                               \n",
        "                          ]),                       \n",
        "                          target_transform=None,download=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7H9H25Zg374D"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(list(cifar_train)[:],\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2,# num_workers는 cpu 코어 개수\n",
        "                                          drop_last=True)\n",
        "test_loader = torch.utils.data.DataLoader(cifar_test,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False, num_workers=2,\n",
        "                                          drop_last=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQ6BCgNmYZ_w"
      },
      "source": [
        "# Model  \n",
        "CNN model은 기존 구성과 동일하며 Dropout을 다 제거하였습니다.  \n",
        "FC-layer는 4096 -> 100 -> 10 으로 마지막에 softmax activation을 추가하였습니다.  \n",
        "또한 RELU activation의 변형인 ELU를 사용하였기 때문에 초기 weight을 HE초기화를 진행하였습니다.  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faQBHpyl4CcK"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "    self.layer = nn.Sequential(\n",
        "        nn.Conv2d(3,16,3,padding=1),\n",
        "        nn.ELU(alpha=1.0),\n",
        "        nn.BatchNorm2d(16),\n",
        "\n",
        "        nn.Conv2d(16,32,3,padding=1),\n",
        "        nn.ELU(alpha=1.0),\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.MaxPool2d(2,2),\n",
        "\n",
        "        nn.Conv2d(32,64,3,padding=1),\n",
        "        nn.ELU(alpha=1.0),\n",
        "        nn.BatchNorm2d(64),\n",
        "\n",
        "        nn.MaxPool2d(2,2)\n",
        "    )\n",
        "    self.fc_layer = nn.Sequential(\n",
        "        nn.Linear(64*8*8,100),\n",
        "        nn.ELU(alpha=1.0),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.BatchNorm1d(100),\n",
        "        nn.Linear(100,10)\n",
        "    )\n",
        "    # Weight initialization\n",
        "    for m in self.modules():\n",
        "      if isinstance(m, nn.Conv2d):\n",
        "        init.kaiming_normal_(m.weight.data)\n",
        "        m.bias.data.fill_(0)\n",
        "      if isinstance(m, nn.Linear):\n",
        "        init.kaiming_normal_(m.weight.data)\n",
        "        m.bias.data.fill_(0)\n",
        "  def forward(self, x):\n",
        "    out = self.layer(x)\n",
        "\n",
        "    out = out.view(batch_size,-1)\n",
        "    out = self.fc_layer(out)\n",
        "    out = nn.functional.log_softmax(out, dim=1)\n",
        "    return out\n",
        "\n",
        "model = CNN().cuda()\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aI0BthsXVxu"
      },
      "source": [
        "# Base Line(without MixUp)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dWumzYy5OuY"
      },
      "source": [
        "# loss_func = nn.CrossEntropyLoss()\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# # scheduler = lr_scheduler.CyclicLR(optimizer, base_lr=1e-3, max_lr=learning_rate, step_size_up=10, \n",
        "# #                      step_size_down=None, mode='triangular2',cycle_momentum=False)\n",
        "# # optimizer = torch.optim.SGD(model.parameters(), lr=0.0001)\n",
        "# # scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, \n",
        "# #                                                 steps_per_epoch=10, epochs=100)\n",
        "\n",
        "# losses=[]\n",
        "# train_acc = []\n",
        "# val_acc = []\n",
        "\n",
        "# #model = CNN().cuda()\n",
        "# Max=0\n",
        "# for i in range(num_epoch):\n",
        "#   model.train()\n",
        "#   print(str(i) + \" epochs\")\n",
        "#   for j, [image, label] in enumerate(train_loader):\n",
        "#     x=Variable(image).cuda()\n",
        "#     y_=Variable(label).cuda()\n",
        "    \n",
        "#     optimizer.zero_grad() # grad가 누적합으로 계산되기 때문에 0으로 초기화\n",
        "#     output=model.forward(x) # 순방향 전파\n",
        "#     loss=loss_func(output,y_) # loss 계산\n",
        "#     loss.backward() # 역전파\n",
        "#     optimizer.step() \n",
        "\n",
        "#   # model training 시각화를 위한 설정\n",
        "#   model.eval()\n",
        "#   tmp = ComputeAccr(test_loader,model)\n",
        "#   val_acc.append(tmp)\n",
        "#   train_acc.append(ComputeAccr(train_loader,model))\n",
        "#   print()\n",
        "#   losses.append(loss)\n",
        "#   if (Max < tmp) and ( i>9 ): # 최고 성능 모델 저장\n",
        "#     Max = tmp\n",
        "#     netname='/content/my_net_'+str(tmp)+'eps'+'.pkl'\n",
        "#     torch.save(model,netname,)\n",
        "# #files.download(netname) # 에폭 다 돌렸을 시 최고 성능 모델 local로 저장"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0ksftqZ90ok"
      },
      "source": [
        "# x = list(range(len(val_acc)))\n",
        "# plt.plot(x, val_acc)\n",
        "# plt.plot(x, train_acc)\n",
        "# plt.show()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wr4nxmF4fASd"
      },
      "source": [
        "# 사용할 learning rate 시각화  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnYPTJmVVMEn"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate, #momentum=0.9,\n",
        "                      weight_decay=weight_decay)\n",
        "scheduler = lr_scheduler.CyclicLR(optimizer, base_lr=learning_rate/2, max_lr=learning_rate*2, step_size_up=10, \n",
        "                     step_size_down=None, mode='triangular2',cycle_momentum=False)\n",
        "\n",
        "lrs=[]\n",
        "for i in range(200):\n",
        "    optimizer.step()\n",
        "    lrs.append(optimizer.param_groups[0][\"lr\"])\n",
        "#     print(\"Factor = \",i,\" , Learning Rate = \",optimizer.param_groups[0][\"lr\"])\n",
        "    scheduler.step()\n",
        "\n",
        "plt.plot(lrs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZTZULakOsi9"
      },
      "source": [
        "# MixUp augmentation  \n",
        "사진 두장을 일정 비율로 혼합하여 사용  \n",
        "label 또한 비율로 설정  \n",
        "optimizer는 adam   \n",
        "l2 regulazation  \n",
        "lr_scheduler= CyclicLR  \n",
        "Augmentation = MixUp, Crop, randomHorizantal flip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzMtwpkz5ofG"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate, #momentum=0.9,\n",
        "                      weight_decay=weight_decay)\n",
        "scheduler = lr_scheduler.CyclicLR(optimizer, base_lr=learning_rate/2, max_lr=learning_rate*2, step_size_up=10, \n",
        "                     step_size_down=None, mode='triangular2',cycle_momentum=False)\n",
        "\n",
        "def mixup_data(x, y, alpha=1.0, use_cuda=True):\n",
        "    '''Returns mixed inputs, pairs of targets, and lambda'''\n",
        "    if alpha > 0:\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "    else:\n",
        "        lam = 1\n",
        "\n",
        "    batch_size = x.size()[0]\n",
        "    if use_cuda:\n",
        "        index = torch.randperm(batch_size).cuda()\n",
        "    else:\n",
        "        index = torch.randperm(batch_size)\n",
        "\n",
        "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
        "    y_a, y_b = y, y[index]\n",
        "    return mixed_x, y_a, y_b, lam\n",
        "\n",
        "\n",
        "def mixup_criterion(criterion, pred, y_a, y_b, lam):  # MixUp augmentation에서의 lossfunction으로 실제 label이 alpha라는 가중치로 설정됨\n",
        "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_E1aDmDcLLXJ"
      },
      "source": [
        "use_cuda = False\n",
        "Max=0\n",
        "losses=[]\n",
        "train_acc = []\n",
        "val_acc = []\n",
        "best_net = []\n",
        "\n",
        "for i in range(num_epoch):\n",
        "  model.train()\n",
        "  print(str(i) + \" epochs\")\n",
        "  for j, [image, label] in enumerate(train_loader):\n",
        "    choice = np.random.rand()\n",
        "    x=Variable(image).cuda()\n",
        "    y_=Variable(label).cuda()\n",
        "    if choice <MixUp_choice: # if use mixup\n",
        "      x, targets_a, targets_b, lam = mixup_data(x, y_,\n",
        "                                              MixUp_alpha, use_cuda)\n",
        "      x, targets_a, targets_b = map(Variable, (x,\n",
        "                                              targets_a, targets_b))\n",
        "      outputs = model(x)\n",
        "      loss = mixup_criterion(criterion, outputs, targets_a, targets_b, lam)\n",
        "      _, predicted = torch.max(outputs.data, 1)  \n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward() \n",
        "      optimizer.step()\n",
        "    else:  # else\n",
        "      optimizer.zero_grad() # grad가 누적합으로 계산되기 때문에 0으로 초기화\n",
        "      output=model.forward(x) # 순방향 전파\n",
        "      loss=criterion(output,y_) # loss 계산\n",
        "      loss.backward() # 역전파\n",
        "      optimizer.step()\n",
        "      \n",
        "  model.eval()\n",
        "  tmp = ComputeAccr(test_loader,model)\n",
        "  val_acc.append(tmp)\n",
        "  train_acc.append(ComputeAccr(train_loader,model))\n",
        "  print()\n",
        "  losses.append(loss)\n",
        "  if (Max < tmp) and ( i>9 ):\n",
        "    Max = tmp\n",
        "    netname='/content/my_bestNet'+'.pkl'\n",
        "    torch.save(model,netname,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s67kI2qfntjc"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate, #momentum=0.9,\n",
        "                      weight_decay=weight_decay)\n",
        "scheduler = lr_scheduler.CyclicLR(optimizer, base_lr=learning_rate/2, max_lr=learning_rate*2, step_size_up=10, \n",
        "                     step_size_down=None, mode='triangular2',cycle_momentum=False)\n",
        "for i in range(num_epoch):\n",
        "  model.train()\n",
        "  print(str(i) + \" epochs\")\n",
        "  for j, [image, label] in enumerate(train_loader):\n",
        "    choice = np.random.rand()\n",
        "    x=Variable(image).cuda()\n",
        "    y_=Variable(label).cuda()\n",
        "    if choice <MixUp_choice: # if use mixup\n",
        "      x, targets_a, targets_b, lam = mixup_data(x, y_,\n",
        "                                              MixUp_alpha, use_cuda)\n",
        "      x, targets_a, targets_b = map(Variable, (x,\n",
        "                                              targets_a, targets_b))\n",
        "      outputs = model(x)\n",
        "      loss = mixup_criterion(criterion, outputs, targets_a, targets_b, lam)\n",
        "      _, predicted = torch.max(outputs.data, 1)  \n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward() \n",
        "      optimizer.step()\n",
        "    else:  # else\n",
        "      optimizer.zero_grad() # grad가 누적합으로 계산되기 때문에 0으로 초기화\n",
        "      output=model.forward(x) # 순방향 전파\n",
        "      loss=criterion(output,y_) # loss 계산\n",
        "      loss.backward() # 역전파\n",
        "      optimizer.step()\n",
        "      \n",
        "  model.eval()\n",
        "  tmp = ComputeAccr(test_loader,model)\n",
        "  val_acc.append(tmp)\n",
        "  train_acc.append(ComputeAccr(train_loader,model))\n",
        "  print()\n",
        "  losses.append(loss)\n",
        "  if (Max < tmp) and ( i>9 ):\n",
        "    Max = tmp\n",
        "    netname='/content/my_bestNet'+'.pkl'\n",
        "    torch.save(model,netname,)\n",
        "files.download(netname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ahtfS5CZG-i"
      },
      "source": [
        "# Visualization  \n",
        "모델의 training을 시각화 하여 학습이 어떻게 진행되는지 각 epoch당 train,test accuracy 그래프로 확인하였습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2oMzJ4gOHko"
      },
      "source": [
        "x = list(range(len(val_acc)))\n",
        "\n",
        "plt.plot(x,val_acc)\n",
        "plt.plot(x, train_acc)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHT-HP47WA-O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "302ec5ae-b4a4-45ac-b978-96602d6294a0"
      },
      "source": [
        "netname ='/content/main2.pkl'\n",
        "eval_model=torch.load(netname)\n",
        "ComputeAccr(test_loader,eval_model)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Test Data: 78.57572174072266\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(78.5757, device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    }
  ]
}