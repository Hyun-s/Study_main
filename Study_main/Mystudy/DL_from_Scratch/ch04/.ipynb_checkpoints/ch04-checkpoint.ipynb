{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebaa8b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-31T07:10:47.764945Z",
     "start_time": "2021-07-31T07:10:47.304253Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from matplotlib import cm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339be0c3",
   "metadata": {},
   "source": [
    "# 손실함수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae36188",
   "metadata": {},
   "source": [
    "## 4.2.1 오차제곱합  \n",
    "$E = {1 \\over 2}\\sum_{k}^{}{(y_{k}-t_{k})^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa81181",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-31T07:10:47.873586Z",
     "start_time": "2021-07-31T07:10:47.866133Z"
    }
   },
   "outputs": [],
   "source": [
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683ffe66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-31T07:10:47.919079Z",
     "start_time": "2021-07-31T07:10:47.905415Z"
    }
   },
   "outputs": [],
   "source": [
    "def sum_squares_error(y, t):\n",
    "    return 0.5 * np.sum((y-t)**2)\n",
    "\n",
    "sum_squares_error(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93096e14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-03T06:26:14.535851Z",
     "start_time": "2021-07-03T06:26:14.519857Z"
    }
   },
   "source": [
    "## 4.2.2 교차 엔트로피 오차\n",
    "$E = -\\sum_{k}^{}{t_{k}logy_{k}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350ebd31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-31T07:10:47.980925Z",
     "start_time": "2021-07-31T07:10:47.966873Z"
    }
   },
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    delta = 1e-7 # if y == 0: log(0) == -inf이기 때문\n",
    "    return -np.sum(t*np.log(y+delta))\n",
    "\n",
    "cross_entropy_error(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa918228",
   "metadata": {},
   "source": [
    "## 4.2.3 미니 배치 학습\n",
    "모든 데이터 말고 일부를 추려 전체의 '근사치'로 학습하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761823e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-31T07:10:48.214653Z",
     "start_time": "2021-07-31T07:10:48.029837Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(t_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9199fcc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-31T07:10:48.230223Z",
     "start_time": "2021-07-31T07:10:48.215581Z"
    }
   },
   "outputs": [],
   "source": [
    "train_size = x_train.shape[0]\n",
    "batch_size = 10\n",
    "batch_mask = np.random.choice(train_size, batch_size) # 이는 데이터셋중 무작위 10개 추출위한 인덱스\n",
    "x_batch = x_train[batch_mask]\n",
    "t_batch = t_train[batch_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2514f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-03T06:32:51.752224Z",
     "start_time": "2021-07-03T06:32:51.739260Z"
    }
   },
   "source": [
    "## 4.2.4 교차 엔트로피 오차 구현  \n",
    "$E = -{1 \\over N} \\sum_{n}^{}{\\sum_{n}^{}{t_{nk}logy_{nk}}}$  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60ec4c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T09:48:45.564706Z",
     "start_time": "2021-07-29T09:48:45.545945Z"
    }
   },
   "source": [
    "- one-hot encoding 되어있는 데이터일 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01685781",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-31T07:10:48.784578Z",
     "start_time": "2021-07-31T07:10:48.743218Z"
    }
   },
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    delta = 1e-7\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(t*np.log(y + delta)) / batch_size\n",
    "\n",
    "cross_entropy_error(np.array(y),np.array(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112fa1f2",
   "metadata": {},
   "source": [
    "- one-hot encoding 안되어있을 때(label-encoding)  \n",
    "  \n",
    "    t*np.log(y) 를 np.log(y[np.arange(batch_size), t] + 1e-7) 로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d9b409",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-31T07:10:49.155408Z",
     "start_time": "2021-07-31T07:10:49.145250Z"
    }
   },
   "outputs": [],
   "source": [
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "def cross_entropy_error(y, t):\n",
    "    delta = 1e-7\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t]+ delta)) / batch_size\n",
    "cross_entropy_error(np.array(y),np.array(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152bbe94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T09:57:22.268608Z",
     "start_time": "2021-07-29T09:57:22.259000Z"
    }
   },
   "source": [
    "## 4.2.5 왜 손실함수를 설정하는가?  \n",
    "정확도를 지표로 삼는 다면 불연속적이기 때문에 미분이 불가능함. 그래서 미분이 가능한 손실함수를 지표로 사용해야한다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadb78da",
   "metadata": {},
   "source": [
    "# 4.3 수치미분"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3e0ba9",
   "metadata": {},
   "source": [
    "## 4.3.1 미분"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494f94c3",
   "metadata": {},
   "source": [
    "- 수치 미분"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ea613b",
   "metadata": {},
   "source": [
    "x 와 x+h인 지점에서의 평균 기울기를 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a421196",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-31T07:10:50.342203Z",
     "start_time": "2021-07-31T07:10:50.323574Z"
    }
   },
   "outputs": [],
   "source": [
    "def numerical_diff(f,x):\n",
    "    h = 1e-4\n",
    "    return (f(x+h)-f(x))/h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ec26bb",
   "metadata": {},
   "source": [
    "위와 같은 코드는 float32자료형을 쓰는데 소수점 8자리까지 표현하지만, 너무 작은 수라 오차가 생긴다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ef3c33",
   "metadata": {},
   "source": [
    "## 4.3.2 수치 미분의 예"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063d8956",
   "metadata": {},
   "source": [
    "$f(x) = 0.01x^2 + 0.1x$  \n",
    "이를 미분해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92de7801",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-31T07:10:51.100262Z",
     "start_time": "2021-07-31T07:10:51.095680Z"
    }
   },
   "outputs": [],
   "source": [
    "def function_1(x):\n",
    "    return 0.01*(x**2) + 0.1*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe426610",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-31T07:10:51.637289Z",
     "start_time": "2021-07-31T07:10:51.352223Z"
    }
   },
   "outputs": [],
   "source": [
    "x = np.arange(0.0, 20.0, 0.1)\n",
    "y = function_1(x)\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59531ece",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T10:01:55.468411Z",
     "start_time": "2021-07-30T10:01:55.448250Z"
    }
   },
   "source": [
    "$f'(x) = 0.02x+0.1$  \n",
    "x 가 5, 10일 때 기울기 = 2,3 으로 아주 근사함을 확인 가능 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8eea72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-31T07:10:51.867368Z",
     "start_time": "2021-07-31T07:10:51.856327Z"
    }
   },
   "outputs": [],
   "source": [
    "print(numerical_diff(function_1,5))\n",
    "print(numerical_diff(function_1,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af3936b",
   "metadata": {},
   "source": [
    "## 4.3.3 편미분"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b5bfc4",
   "metadata": {},
   "source": [
    "변수가 2개인 경우  \n",
    "$f(x_{0},x_{1}) = x_{0}^{2} + x_{1}^{2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8a3779",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-31T07:23:23.535876Z",
     "start_time": "2021-07-31T07:23:23.521828Z"
    }
   },
   "outputs": [],
   "source": [
    "def function_2(x):\n",
    "    return np.sum(x**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61834b14",
   "metadata": {},
   "source": [
    "$x_{0} = 3, x_{1}=4$일 때 기울기를 구하라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be7e8aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-31T07:23:30.226101Z",
     "start_time": "2021-07-31T07:23:30.214437Z"
    }
   },
   "outputs": [],
   "source": [
    "def function_tmp1(x0): # x1 을 4로 고정\n",
    "    return x0*x0 + 4.0**2.0\n",
    "print(numerical_diff(function_tmp1,3.0))\n",
    "\n",
    "def function_tmp2(x1): # x0 를 3으로 고정\n",
    "    return 3.0**2.0 + x1*x1\n",
    "\n",
    "print(numerical_diff(function_tmp2,4.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a04ccb8",
   "metadata": {},
   "source": [
    "## 4.4기울기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8274ebf3",
   "metadata": {},
   "source": [
    "편미분을 동시에 계산하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b843ed97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-31T07:35:58.578335Z",
     "start_time": "2021-07-31T07:35:58.559074Z"
    }
   },
   "outputs": [],
   "source": [
    "def _numerical_gradient_no_batch(f,x): # 한개씩 계산 가능 배치 없이\n",
    "    h = 1e-4\n",
    "    grad = np.zeros_like(x) # 변수 개수만큼 배열 생성 기울기 벡터가 변수 개수만큼 가짐\n",
    "    for idx in range(x.size):\n",
    "        tmp_val = x[idx]\n",
    "        \n",
    "        x[idx] = tmp_val + h\n",
    "        fxh1 = f(x) # f(x+h)\n",
    "        x[idx] = tmp_val - h\n",
    "        fxh2 = f(x) # f(x-h)\n",
    "        \n",
    "        grad[idx] = (fxh1-fxh2) / (2*h)\n",
    "        x[idx] = tmp_val # 위에서 x 값을 변경했기 때문에 다시 원래값으로 복원\n",
    "    return grad\n",
    "\n",
    "def numerical_gradient(f, X):\n",
    "    if X.ndim == 1:\n",
    "        return _numerical_gradient_no_batch(f, X)\n",
    "    else:\n",
    "        grad = np.zeros_like(X)\n",
    "        \n",
    "        for idx, x in enumerate(X):\n",
    "            grad[idx] = _numerical_gradient_no_batch(f, x)\n",
    "        \n",
    "        return grad\n",
    "numerical_gradient(function_2,np.array([3.0,4.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3968a2dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-31T07:36:01.844395Z",
     "start_time": "2021-07-31T07:36:01.831118Z"
    }
   },
   "outputs": [],
   "source": [
    "def function_2(x):\n",
    "    if x.ndim == 1:\n",
    "        return np.sum(x**2)\n",
    "    else:\n",
    "        return np.sum(x**2, axis=1)\n",
    "\n",
    "\n",
    "def tangent_line(f, x):\n",
    "    d = numerical_gradient(f, x)\n",
    "    print(d)\n",
    "    y = f(x) - d*x\n",
    "    return lambda t: d*t + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d9f16a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-31T07:36:02.379293Z",
     "start_time": "2021-07-31T07:36:02.022257Z"
    }
   },
   "outputs": [],
   "source": [
    "x0 = np.arange(-2, 2.5, 0.25)\n",
    "x1 = np.arange(-2, 2.5, 0.25)\n",
    "X, Y = np.meshgrid(x0, x1)\n",
    "\n",
    "X = X.flatten()\n",
    "Y = Y.flatten()\n",
    "\n",
    "grad = numerical_gradient(function_2, np.array([X, Y]) )\n",
    "\n",
    "plt.figure()\n",
    "plt.quiver(X, Y, -grad[0], -grad[1],  angles=\"xy\",color=\"#666666\")\n",
    "plt.xlim([-2, 2])\n",
    "plt.ylim([-2, 2])\n",
    "plt.xlabel('$x_0$')\n",
    "plt.ylabel('$x_1$')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.draw()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcb2acd",
   "metadata": {},
   "source": [
    "## 4.4.1 경사하강법(Gradient Descent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099e9ef0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-31T07:38:52.581679Z",
     "start_time": "2021-07-31T07:38:52.572679Z"
    }
   },
   "source": [
    "기울기를 이용하여 매개변수의 공간의 최소점을 찾자  \n",
    "$x_{0} = x_{0} - \\eta{\\delta f \\over \\delta x_{0}}$  \n",
    "$x_{1} = x_{1} - \\eta{\\delta f \\over \\delta x_{1}}$  \n",
    "  \n",
    "$\\eta$ 는 얼마나 갱신할 지, 즉 Learning Rate * 지점에서의 기울기를 뺌으로서 갱신한다.    \n",
    "learning rate의 경우 너무 크면 발산하게 되고 너무 작으면 수렴하지 못하는 문제점이 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ceaa519",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-31T08:18:42.546253Z",
     "start_time": "2021-07-31T08:18:42.541921Z"
    }
   },
   "outputs": [],
   "source": [
    "def gradient_descent(f, init_x, lr=0.01, step_num=100):\n",
    "    x = init_x\n",
    "    \n",
    "    for i in range(step_num):\n",
    "        grad = numerical_gradient(f, x) # 스텝만큼 기울기 구함\n",
    "        x -= lr*grad # x 갱신\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e511f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-31T08:18:43.058043Z",
     "start_time": "2021-07-31T08:18:43.026793Z"
    }
   },
   "outputs": [],
   "source": [
    "def function_2(x):\n",
    "    return x[0]**2 + x[1]**2\n",
    "\n",
    "init_x = np.array([-3.0, 4.0])\n",
    "\n",
    "gradient_descent(function_2, init_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8112a0d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-31T08:18:45.108756Z",
     "start_time": "2021-07-31T08:18:45.013361Z"
    }
   },
   "outputs": [],
   "source": [
    "init_x = np.array([-3.0, 4.0])\n",
    "def gradient_descent_dr(f, init_x, lr=0.1, step_num=10):\n",
    "    x = init_x\n",
    "    tmp = []\n",
    "    for i in range(step_num):\n",
    "        tmp.append(x.copy())\n",
    "        grad = numerical_gradient(f, x) # 스텝만큼 기울기 구함\n",
    "        x -= lr*grad # x 갱신\n",
    "    return x, np.array(tmp)\n",
    "x, tmp = gradient_descent_dr(function_2, init_x)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(tmp[:,0],tmp[:,1],c=np.arange(len(tmp)))\n",
    "plt.scatter(0.,0.,marker = '^',c = 'r',s=1000)\n",
    "plt.grid()\n",
    "plt.xlim(-5,5)\n",
    "plt.ylim(-5,5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8a1459",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-31T08:07:12.480660Z",
     "start_time": "2021-07-31T08:07:12.450337Z"
    }
   },
   "source": [
    "## 4.4.2 신경망에서의 기울기  \n",
    "$\n",
    "W = \\left( \n",
    "    \\begin{matrix}  \n",
    "            w_{11} & w_{12} & w_{13}\\\\\n",
    "            w_{21} & w_{22} & w_{23}\\\\\n",
    "    \\end{matrix} \n",
    "    \\right)  \n",
    "$  \n",
    "  \n",
    "$\n",
    "{\\delta L \\over \\delta W}= \\left( \n",
    "    \\begin{matrix}  \n",
    "            {\\delta L \\over \\delta w_{11}} & {\\delta L \\over \\delta w_{12}} & {\\delta L \\over \\delta w_{13}}\\\\\n",
    "            {\\delta L \\over \\delta w_{21}} & {\\delta L \\over \\delta w_{22}} & {\\delta L \\over \\delta w_{23}}\\\\\n",
    "    \\end{matrix} \n",
    "    \\right)\n",
    "$  \n",
    "  \n",
    "$W$ 는 가중치 행렬, ${\\delta L \\over \\delta W}$는 가중치의 편미분 행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b16a322",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-31T08:39:57.158431Z",
     "start_time": "2021-07-31T08:39:57.133365Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "from common.functions import softmax, cross_entropy_error\n",
    "from common.gradient import numerical_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73027fd0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-31T08:52:37.674664Z",
     "start_time": "2021-07-31T08:52:37.662695Z"
    }
   },
   "outputs": [],
   "source": [
    "class simpleNet:\n",
    "    def __init__(self):\n",
    "        self.W = np.random.randn(2,3) # w.shape(2,3) 정규분포로 초기화\n",
    "        \n",
    "    def predict(self, x):\n",
    "        return np.dot(x,self.W)\n",
    "    \n",
    "    def loss(self,x,t):\n",
    "        z = self.predict(x)\n",
    "        y = softmax(z)\n",
    "        loss = cross_entropy_error(y,t)\n",
    "        return loss\n",
    "    \n",
    "    def back_propagation(self,dW):\n",
    "        self.W = self.W-dW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa764cdb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-31T08:46:38.187691Z",
     "start_time": "2021-07-31T08:46:38.170541Z"
    }
   },
   "outputs": [],
   "source": [
    "net = simpleNet()\n",
    "print(net.W) # 가중치 행렬\n",
    "\n",
    "x = np.array([0.6,0.9])\n",
    "p = net.predict(x)\n",
    "print('probability',p) # [1,2] * [2,3] = [1,3] 행렬 연산 shape\n",
    "\n",
    "print(np.argmax(p))\n",
    "\n",
    "t = np.array([0,0,1])\n",
    "print(net.loss(x,t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c6f39a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-31T08:56:31.578273Z",
     "start_time": "2021-07-31T08:56:31.566333Z"
    }
   },
   "outputs": [],
   "source": [
    "def f(W):\n",
    "    return net.loss(x,t)\n",
    "def pred(x):\n",
    "    return np.argmax(net.predict(x))\n",
    "\n",
    "dW = numerical_gradient(f,net.W)\n",
    "print(dW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e3d36e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-31T08:57:09.128779Z",
     "start_time": "2021-07-31T08:57:09.105519Z"
    }
   },
   "outputs": [],
   "source": [
    "net = simpleNet()\n",
    "x = np.array([0.6,0.9])\n",
    "t = np.array([0,0,1])\n",
    "f = lambda w : net.loss(x,t)\n",
    "\n",
    "for step in range(10):\n",
    "    print('loss:',net.loss(x,t))\n",
    "    dW = numerical_gradient(f,net.W)\n",
    "    net.back_propagation(dW)\n",
    "    \n",
    "print('predict = ',pred(x))\n",
    "print('real = ',np.argmax(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991aa522",
   "metadata": {},
   "source": [
    "## 4.5.1 2층 신경망 클래스 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6727427e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-08T04:12:57.061537Z",
     "start_time": "2021-08-08T04:12:57.039636Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "from common.functions import *\n",
    "from common.gradient import numerical_gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50958c90",
   "metadata": {},
   "source": [
    "$((input\\_size , hidden\\_size) + (hidden\\_size)) \\times (hidden\\_size, output\\_size) + (output\\_size)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fba9fc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-08T04:51:17.212053Z",
     "start_time": "2021-08-08T04:51:17.190325Z"
    }
   },
   "outputs": [],
   "source": [
    "class TwoLayerNet:\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size) # 난수로 (input x hidden 배열생성)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        \n",
    "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        # weight, bias\n",
    "        W1, W2 = self.params['W1'], self.params['W2']\n",
    "        b1, b2 = self.params['b1'], self.params['b2']\n",
    "        \n",
    "        # calc\n",
    "        a1 = np.dot(x, W1) + b1 # first layer(Dense) , in TF layers.Dense(hidden_size)\n",
    "        z1 = sigmoid(a1) # activation\n",
    "        a2 = np.dot(a1,W2) + b2 # second layer(dense)\n",
    "        y = softmax(a2)\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        \n",
    "        return cross_entropy_error(y,t) # loss \n",
    "    \n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        t = np.argmax(t, axis=1)\n",
    "        \n",
    "        acc = np.sum(y == t) / float(x.shape[0]) # y==t인 것들 합 / 데이터 개수\n",
    "        return acc\n",
    "\n",
    "    # back propagation을 위한 gradient dict, 수치미분을 이용한 계산\n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_W = lambda W: self.loss(x, t)\n",
    "        \n",
    "        grads = {}\n",
    "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
    "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
    "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
    "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
    "        \n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dc7ada",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-08T04:51:18.144586Z",
     "start_time": "2021-08-08T04:51:18.141663Z"
    }
   },
   "outputs": [],
   "source": [
    "# net = TwoLayerNet(784,512,10)\n",
    "\n",
    "# from two_layer_net import TwoLayerNet\n",
    "# net = TwoLayerNet(784,512,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fb5fe0",
   "metadata": {},
   "source": [
    "## 4.5.2 미니배치 학습 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d831037a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-08T05:11:26.356059Z",
     "start_time": "2021-08-08T05:11:26.319486Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "from two_layer_net import TwoLayerNet\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62500709",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-08T05:11:47.152Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                              | 3/1000 [01:12<6:47:59, 24.55s/it]"
     ]
    }
   ],
   "source": [
    "# test data 사용안함\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "train_loss_list = []\n",
    "\n",
    "iters_num = 1000\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "for i in tqdm.tqdm(range(iters_num)):\n",
    "    # 배치 추출\n",
    "    batch_mask = np.random.choice(train_size, batch_size) # 배치로 사용할 인덱스들\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    grad = network.numerical_gradient(x_batch, t_batch) # 수치미분\n",
    "#     grad = network.gradient(x_batch, t_batch) # 오차 역전파 성능 더 좋음\n",
    "    \n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate*grad[key] # 기울기만큼 파라미터 수정\n",
    "        \n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4057321",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(range(1, len(train_loss_list)+1))\n",
    "plt.plot(x, train_loss_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033cab67",
   "metadata": {},
   "source": [
    "## 4.5.3 시험 데이터로 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15fbef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "from two_layer_net import TwoLayerNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc16b790",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "iters_num = 10000\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    # 배치 추출\n",
    "    batch_mask = np.random.choice(train_size, batch_size) # 배치로 사용할 인덱스들\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    grad = network.numerical_gradient(x_batch, t_batch) # 수치미분\n",
    "#     grad = network.gradient(x_batch, t_batch) # 오차 역전파 성능 더 좋음\n",
    "    \n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate*grad[key] # 기울기만큼 파라미터 수정\n",
    "        \n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print('train acc, test acc | '+ str(train_acc)+ ', '+str(test_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
