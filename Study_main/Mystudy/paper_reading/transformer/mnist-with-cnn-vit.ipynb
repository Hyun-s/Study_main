{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install tensorflow-addons","metadata":{"execution":{"iopub.status.busy":"2021-09-21T09:35:22.605045Z","iopub.execute_input":"2021-09-21T09:35:22.605701Z","iopub.status.idle":"2021-09-21T09:35:30.277956Z","shell.execute_reply.started":"2021-09-21T09:35:22.605618Z","shell.execute_reply":"2021-09-21T09:35:30.276969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import (\n    Conv2D, BatchNormalization, Dropout, MaxPool2D,#Normalization,\n    Flatten, Dense, Input, Concatenate, LeakyReLU, Add\n)\nimport tensorflow_addons as tfa\n\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2021-09-23T02:29:49.525284Z","iopub.execute_input":"2021-09-23T02:29:49.525578Z","iopub.status.idle":"2021-09-23T02:29:54.708839Z","shell.execute_reply.started":"2021-09-23T02:29:49.525494Z","shell.execute_reply":"2021-09-23T02:29:54.708021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_shape = (28,28,1)\nepochs = 100\nbatch = 16","metadata":{"execution":{"iopub.status.busy":"2021-09-23T02:29:54.7105Z","iopub.execute_input":"2021-09-23T02:29:54.710758Z","iopub.status.idle":"2021-09-23T02:29:54.718095Z","shell.execute_reply.started":"2021-09-23T02:29:54.710724Z","shell.execute_reply":"2021-09-23T02:29:54.717158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/digit-recognizer/train.csv')\ntest = pd.read_csv('../input/digit-recognizer/test.csv')\n\nsub = pd.read_csv('../input/digit-recognizer/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-09-23T02:29:54.719693Z","iopub.execute_input":"2021-09-23T02:29:54.719985Z","iopub.status.idle":"2021-09-23T02:29:59.843511Z","shell.execute_reply.started":"2021-09-23T02:29:54.719934Z","shell.execute_reply":"2021-09-23T02:29:59.842669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testing = test.to_numpy().reshape(28000,28,28,1)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T02:29:59.8465Z","iopub.execute_input":"2021-09-23T02:29:59.847218Z","iopub.status.idle":"2021-09-23T02:29:59.851436Z","shell.execute_reply.started":"2021-09-23T02:29:59.847174Z","shell.execute_reply":"2021-09-23T02:29:59.850547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = train.iloc[:,1:]\ny = train.iloc[:,:1]","metadata":{"execution":{"iopub.status.busy":"2021-09-23T02:29:59.852411Z","iopub.execute_input":"2021-09-23T02:29:59.852849Z","iopub.status.idle":"2021-09-23T02:29:59.866946Z","shell.execute_reply.started":"2021-09-23T02:29:59.852812Z","shell.execute_reply":"2021-09-23T02:29:59.866245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_x, val_x, train_y,val_y = train_test_split(x,y, test_size=0.2,\n                                                stratify=y)\n\nprint(train_x.shape,train_y.shape)\nprint(val_x.shape,val_y.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T02:29:59.868176Z","iopub.execute_input":"2021-09-23T02:29:59.868487Z","iopub.status.idle":"2021-09-23T02:30:00.339244Z","shell.execute_reply.started":"2021-09-23T02:29:59.868453Z","shell.execute_reply":"2021-09-23T02:30:00.338468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def gen(data_x,data_y):\n    for x in range(len(data_x)):\n        y = np.zeros(10)\n        tmp = data_x[x]\n        input_ = tmp.reshape(img_shape)/255.\n        y[int(data_y[x][0])] = 1.\n        input_ = tf.convert_to_tensor(input_,dtype=tf.float32)\n        y = tf.convert_to_tensor(y,dtype=tf.float32)\n        yield input_,y","metadata":{"execution":{"iopub.status.busy":"2021-09-23T02:30:00.340427Z","iopub.execute_input":"2021-09-23T02:30:00.341082Z","iopub.status.idle":"2021-09-23T02:30:00.347311Z","shell.execute_reply.started":"2021-09-23T02:30:00.341044Z","shell.execute_reply":"2021-09-23T02:30:00.346527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = tf.data.Dataset.from_generator(gen,\n                                         (tf.float32,tf.float32),\n                                         ((img_shape),(10)),\n                                         args=(train_x,train_y))\nval_dataset = tf.data.Dataset.from_generator(gen,\n                                         (tf.float32,tf.float32),\n                                         (img_shape,(10)),\n                                         args=(val_x,val_y))\ntrain_dataset = train_dataset.shuffle(128).batch(batch)\nval_dataset = val_dataset.shuffle(128).batch(batch)\nfor example in train_dataset.take(1):\n    plt.subplot(2,1,1)\n    image, label = example\n    plt.imshow(image[0])\n    plt.title(str(np.argmax(label)))\n    \nfor example in val_dataset.take(1):\n    plt.subplot(2,1,2)\n    image, label = example\n    plt.imshow(image[0])\n    plt.title(str(np.argmax(label)))    \n    \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-23T02:30:00.348474Z","iopub.execute_input":"2021-09-23T02:30:00.34915Z","iopub.status.idle":"2021-09-23T02:30:04.434953Z","shell.execute_reply.started":"2021-09-23T02:30:00.349113Z","shell.execute_reply":"2021-09-23T02:30:04.434289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Basic CNN","metadata":{}},{"cell_type":"code","source":"def makemodel():\n    model = Sequential()\n    model.add(Conv2D(32, kernel_size = 3, activation='relu', input_shape = (28, 28, 1)))\n    model.add(Conv2D(32, kernel_size = 3, activation='relu'))\n    model.add(Conv2D(32, kernel_size = 5, strides=2, padding='same', activation='relu'))\n\n    model.add(Flatten())\n    model.add(Dropout(0.4))\n    model.add(Dense(10, activation='softmax'))\n\n    # COMPILE WITH ADAM OPTIMIZER AND CROSS ENTROPY COST\n    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-09-21T09:35:40.809477Z","iopub.execute_input":"2021-09-21T09:35:40.8099Z","iopub.status.idle":"2021-09-21T09:35:40.820259Z","shell.execute_reply.started":"2021-09-21T09:35:40.809853Z","shell.execute_reply":"2021-09-21T09:35:40.819338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn_model = makemodel()\ncnn_history = cnn_model.fit(\n    train_dataset,validation_data=val_dataset,\n    epochs=epochs, \n    verbose=1\n)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T09:36:39.740616Z","iopub.execute_input":"2021-09-21T09:36:39.741257Z","iopub.status.idle":"2021-09-21T09:37:07.581631Z","shell.execute_reply.started":"2021-09-21T09:36:39.741203Z","shell.execute_reply":"2021-09-21T09:37:07.580569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* * *","metadata":{"execution":{"iopub.status.busy":"2021-09-21T06:52:59.017621Z","iopub.execute_input":"2021-09-21T06:52:59.018249Z","iopub.status.idle":"2021-09-21T06:52:59.023381Z","shell.execute_reply.started":"2021-09-21T06:52:59.018198Z","shell.execute_reply":"2021-09-21T06:52:59.02237Z"}}},{"cell_type":"markdown","source":"## VIT  \n[reference](https://keras.io/examples/vision/image_classification_with_vision_transformer/)","metadata":{}},{"cell_type":"code","source":"input_shape = (28,28,1)\nlearning_rate = 0.001\nweight_decay = 0.0001\nbatch_size = 16\nnum_epochs = 100\nimage_size = 72  # We'll resize input images to this size\npatch_size = 6  # Size of the patches to be extract from the input images\nnum_patches = (image_size // patch_size) ** 2\nprojection_dim = 64\nnum_heads = 4\ntransformer_units = [\n    projection_dim * 2,\n    projection_dim,\n]  # Size of the transformer layers\ntransformer_layers = 8\nmlp_head_units = [2048, 1024]  # Size of the dense layers of the final classifier","metadata":{"execution":{"iopub.status.busy":"2021-09-21T09:37:21.777007Z","iopub.execute_input":"2021-09-21T09:37:21.777345Z","iopub.status.idle":"2021-09-21T09:37:21.784887Z","shell.execute_reply.started":"2021-09-21T09:37:21.77731Z","shell.execute_reply":"2021-09-21T09:37:21.783694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def gen(data_x,data_y):\n    for x in range(len(data_x)):\n        y = np.zeros(10)\n        tmp = data_x[x]\n        input_ = tmp.reshape(img_shape)/255.\n        y[int(data_y[x][0])] = 1.\n        input_ = tf.convert_to_tensor(input_,dtype=tf.float32)\n        y = tf.convert_to_tensor(y,dtype=tf.float32)\n        yield input_,data_y[x]\n        \ntrain_dataset = tf.data.Dataset.from_generator(gen,\n                                         (tf.float32,tf.float32),\n                                         ((img_shape),(1)),\n                                         args=(train_x,train_y))\nval_dataset = tf.data.Dataset.from_generator(gen,\n                                         (tf.float32,tf.float32),\n                                         (img_shape,(1)),\n                                         args=(val_x,val_y))\ntrain_dataset = train_dataset.shuffle(128).batch(batch_size)\nval_dataset = val_dataset.shuffle(128).batch(batch_size)\n\nfor image, label in train_dataset.take(1):\n    print(label)\n    for i in range(batch_size):\n        plt.subplot(4,4,i+1)\n        plt.imshow(image[i])\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-21T09:37:22.080402Z","iopub.execute_input":"2021-09-21T09:37:22.081027Z","iopub.status.idle":"2021-09-21T09:37:24.79348Z","shell.execute_reply.started":"2021-09-21T09:37:22.080993Z","shell.execute_reply":"2021-09-21T09:37:24.792722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_augmentation = keras.Sequential(\n    [\n        layers.experimental.preprocessing.Normalization(),\n        layers.experimental.preprocessing.Resizing(image_size, image_size),\n        layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n        layers.experimental.preprocessing.RandomRotation(factor=0.02),\n        layers.experimental.preprocessing.RandomZoom(\n            height_factor=0.2, width_factor=0.2\n        ),\n    ],\n    name=\"data_augmentation\",\n)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T09:37:24.795081Z","iopub.execute_input":"2021-09-21T09:37:24.795878Z","iopub.status.idle":"2021-09-21T09:37:24.836949Z","shell.execute_reply.started":"2021-09-21T09:37:24.795826Z","shell.execute_reply":"2021-09-21T09:37:24.836097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def mlp(x, hidden_units, dropout_rate):\n    for units in hidden_units:\n        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n        x = layers.Dropout(dropout_rate)(x)\n    return x","metadata":{"execution":{"iopub.status.busy":"2021-09-21T09:37:24.838195Z","iopub.execute_input":"2021-09-21T09:37:24.838888Z","iopub.status.idle":"2021-09-21T09:37:24.845527Z","shell.execute_reply.started":"2021-09-21T09:37:24.838795Z","shell.execute_reply":"2021-09-21T09:37:24.844395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Patches(layers.Layer):\n    def __init__(self, patch_size):\n        super(Patches, self).__init__()\n        self.patch_size = patch_size\n\n    def call(self, images):\n        batch_size = tf.shape(images)[0]\n        patches = tf.image.extract_patches(\n            images=images,\n            sizes=[1, self.patch_size, self.patch_size, 1],\n            strides=[1, self.patch_size, self.patch_size, 1],\n            rates=[1, 1, 1, 1],\n            padding=\"VALID\",\n        )\n        patch_dims = patches.shape[-1]\n        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n        return patches","metadata":{"execution":{"iopub.status.busy":"2021-09-21T09:37:24.848602Z","iopub.execute_input":"2021-09-21T09:37:24.848989Z","iopub.status.idle":"2021-09-21T09:37:24.860207Z","shell.execute_reply.started":"2021-09-21T09:37:24.848949Z","shell.execute_reply":"2021-09-21T09:37:24.85907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(4, 4))\nimage = train_x.iloc[0].to_numpy().reshape((28,28,1))\nplt.imshow(image.astype(\"uint8\"))\nplt.axis(\"off\")\n\nresized_image = tf.image.resize(\n    tf.convert_to_tensor([image]), size=(image_size, image_size)\n)\npatches = Patches(patch_size)(resized_image)\nprint(f\"Image size: {image_size} X {image_size}\")\nprint(f\"Patch size: {patch_size} X {patch_size}\")\nprint(f\"Patches per image: {patches.shape[1]}\")\nprint(f\"Elements per patch: {patches.shape[-1]}\")\n\nn = int(np.sqrt(patches.shape[1]))\nplt.figure(figsize=(4, 4))\nfor i, patch in enumerate(patches[0]):\n    ax = plt.subplot(n, n, i + 1)\n    patch_img = tf.reshape(patch, (patch_size, patch_size, 1))\n    plt.imshow(patch_img.numpy().astype(\"uint8\"))\n    plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2021-09-21T09:37:24.862443Z","iopub.execute_input":"2021-09-21T09:37:24.862918Z","iopub.status.idle":"2021-09-21T09:37:31.815012Z","shell.execute_reply.started":"2021-09-21T09:37:24.862876Z","shell.execute_reply":"2021-09-21T09:37:31.814157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PatchEncoder(layers.Layer):\n    def __init__(self, num_patches, projection_dim):\n        super(PatchEncoder, self).__init__()\n        self.num_patches = num_patches\n        self.projection = layers.Dense(units=projection_dim)\n        self.position_embedding = layers.Embedding(\n            input_dim=num_patches, output_dim=projection_dim\n        )\n\n    def call(self, patch):\n        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n        encoded = self.projection(patch) + self.position_embedding(positions)\n        return encoded","metadata":{"execution":{"iopub.status.busy":"2021-09-21T09:37:31.816602Z","iopub.execute_input":"2021-09-21T09:37:31.817105Z","iopub.status.idle":"2021-09-21T09:37:31.825371Z","shell.execute_reply.started":"2021-09-21T09:37:31.817065Z","shell.execute_reply":"2021-09-21T09:37:31.824457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_vit_classifier():\n    inputs = layers.Input(shape=input_shape)\n    # Augment data.\n    augmented = data_augmentation(inputs)\n    # Create patches.\n    patches = Patches(patch_size)(augmented)\n    # Encode patches.\n    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n\n    # Create multiple layers of the Transformer block.\n    for _ in range(transformer_layers):\n        # Layer normalization 1.\n        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n        # Create a multi-head attention layer.\n        attention_output = layers.MultiHeadAttention(\n            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n        )(x1, x1)\n        # Skip connection 1.\n        x2 = layers.Add()([attention_output, encoded_patches])\n        # Layer normalization 2.\n        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n        # MLP.\n        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n        # Skip connection 2.\n        encoded_patches = layers.Add()([x3, x2])\n\n    # Create a [batch_size, projection_dim] tensor.\n    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n    representation = layers.Flatten()(representation)\n    representation = layers.Dropout(0.5)(representation)\n    # Add MLP.\n    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n    # Classify outputs.\n    logits = layers.Dense(10)(features)\n    # Create the Keras model.\n    model = keras.Model(inputs=inputs, outputs=logits)\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-09-21T09:37:31.827885Z","iopub.execute_input":"2021-09-21T09:37:31.828169Z","iopub.status.idle":"2021-09-21T09:37:31.841527Z","shell.execute_reply.started":"2021-09-21T09:37:31.828135Z","shell.execute_reply":"2021-09-21T09:37:31.840594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_experiment(model):\n    optimizer = tfa.optimizers.AdamW(\n        learning_rate=learning_rate, weight_decay=weight_decay\n    )\n\n    model.compile(\n        optimizer=optimizer,\n        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n        metrics=[\n            keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n            keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n        ],\n    )\n\n    checkpoint_filepath = \"./\"\n    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n        checkpoint_filepath,\n        monitor=\"val_accuracy\",\n        save_best_only=True,\n        save_weights_only=True,\n    )\n\n    history = model.fit(\n        train_dataset,validation_data=val_dataset,\n        batch_size=batch_size,\n        epochs=num_epochs,\n        callbacks=[checkpoint_callback],\n    )\n\n    model.load_weights(checkpoint_filepath)\n    _, accuracy, top_5_accuracy = model.evaluate(val_dataset)\n    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n    print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n    return history","metadata":{"execution":{"iopub.status.busy":"2021-09-21T10:02:15.893645Z","iopub.execute_input":"2021-09-21T10:02:15.893942Z","iopub.status.idle":"2021-09-21T10:02:15.902984Z","shell.execute_reply.started":"2021-09-21T10:02:15.89391Z","shell.execute_reply":"2021-09-21T10:02:15.902026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vit_classifier = create_vit_classifier()\nvit_history = run_experiment(vit_classifier)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T09:37:31.857166Z","iopub.execute_input":"2021-09-21T09:37:31.857476Z","iopub.status.idle":"2021-09-21T09:57:35.804744Z","shell.execute_reply.started":"2021-09-21T09:37:31.857442Z","shell.execute_reply":"2021-09-21T09:57:35.803279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = create_vit_classifier()\nmodel.load_weights('./')","metadata":{"execution":{"iopub.status.busy":"2021-09-21T10:03:44.662697Z","iopub.execute_input":"2021-09-21T10:03:44.663466Z","iopub.status.idle":"2021-09-21T10:03:46.20348Z","shell.execute_reply.started":"2021-09-21T10:03:44.663431Z","shell.execute_reply":"2021-09-21T10:03:46.202757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = model.predict(testing)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T10:04:46.38012Z","iopub.execute_input":"2021-09-21T10:04:46.380672Z","iopub.status.idle":"2021-09-21T10:04:55.782815Z","shell.execute_reply.started":"2021-09-21T10:04:46.380631Z","shell.execute_reply":"2021-09-21T10:04:55.781947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = []\nfor x in pred:\n    preds.append(np.argmax(x))","metadata":{"execution":{"iopub.status.busy":"2021-09-21T10:06:06.864815Z","iopub.execute_input":"2021-09-21T10:06:06.865374Z","iopub.status.idle":"2021-09-21T10:06:06.960289Z","shell.execute_reply.started":"2021-09-21T10:06:06.865339Z","shell.execute_reply":"2021-09-21T10:06:06.959493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = test.to_numpy()\ndef gen(data_x):\n    for x in range(len(data_x)):\n        y = np.zeros(10)\n        tmp = data_x[x]\n        input_ = tmp.reshape(img_shape)/255.\n        y[int(data_y[x][0])] = 1.\n        input_ = tf.convert_to_tensor(input_,dtype=tf.float32)\n        y = tf.convert_to_tensor(y,dtype=tf.float32)\n        yield input_\n        \ntest_dataset = tf.data.Dataset.from_generator(gen,\n                                         (tf.float32),\n                                         (img_shape),\n                                         args=(test))\ntrain_dataset = train_dataset.batch(batch)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T02:31:52.144781Z","iopub.execute_input":"2021-09-23T02:31:52.145059Z","iopub.status.idle":"2021-09-23T02:31:52.17554Z","shell.execute_reply.started":"2021-09-23T02:31:52.145027Z","shell.execute_reply":"2021-09-23T02:31:52.174406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-09-21T10:06:49.93671Z","iopub.execute_input":"2021-09-21T10:06:49.937502Z","iopub.status.idle":"2021-09-21T10:06:49.95705Z","shell.execute_reply.started":"2021-09-21T10:06:49.937464Z","shell.execute_reply":"2021-09-21T10:06:49.956132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.to_csv('sub.csv')","metadata":{"execution":{"iopub.status.busy":"2021-09-21T10:07:10.616684Z","iopub.execute_input":"2021-09-21T10:07:10.617312Z","iopub.status.idle":"2021-09-21T10:07:10.701124Z","shell.execute_reply.started":"2021-09-21T10:07:10.617276Z","shell.execute_reply":"2021-09-21T10:07:10.700305Z"},"trusted":true},"execution_count":null,"outputs":[]}]}